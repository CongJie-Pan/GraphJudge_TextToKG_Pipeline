"""
Lightweight Type Annotator for ECTD Pipeline

This script implements a lightweight entity type annotation system that assigns
semantic types to extracted entities using rule-based patterns and regex matching.
The annotation system is optimized for classical Chinese literature, particularly
"Dream of the Red Chamber" (Á¥ÖÊ®ìÂ§¢), and supports standard entity types.

Key Features:
1. Rule-based type assignment using regex patterns
2. Support for multiple entity types: PERSON, LOCATION, CONCEPT, OBJECT, etc.
3. Classical Chinese name pattern recognition
4. Location and geographical pattern matching
5. Abstract concept and literary device recognition
6. TSV output format for downstream processing
7. Confidence scoring for type assignments
8. Extensible pattern configuration system

Entity Types Supported:
- PERSON: Character names, titles, roles
- LOCATION: Places, geographical locations, buildings
- CONCEPT: Abstract concepts, emotions, ideas
- OBJECT: Physical objects, items, artifacts
- ORGANIZATION: Groups, institutions, family lines
- EVENT: Actions, occurrences, incidents
- TEMPORAL: Time-related entities
- LITERARY: Literary devices, narrative elements

Usage:
    from tools.type_annotator import TypeAnnotator
    
    annotator = TypeAnnotator()
    typed_entities = annotator.annotate_entities_file("test_entity.txt")
    annotator.save_typed_entities(typed_entities, "test_entity_typed.tsv")

Command Line Usage:
    python tools/type_annotator.py --input test_entity.txt --output test_entity_typed.tsv
"""

import os
import re
import json
import argparse
import logging
from pathlib import Path
from typing import List, Dict, Set, Tuple, Optional, Union
from dataclasses import dataclass
from collections import defaultdict


@dataclass
class EntityAnnotation:
    """
    Data class representing a typed entity annotation.
    
    This class encapsulates all information about an annotated entity,
    including the original text, assigned type, confidence score, and
    matching pattern information for traceability.
    """
    entity: str                    # Original entity text
    entity_type: str              # Assigned type (PERSON, LOCATION, etc.)
    confidence: float             # Confidence score (0.0 to 1.0)
    pattern_matched: str          # Pattern that triggered the assignment
    pattern_category: str         # Category of the matching pattern
    
    def to_tsv_row(self) -> str:
        """Convert annotation to TSV format row."""
        return f"{self.entity}\t{self.entity_type}\t{self.confidence:.3f}\t{self.pattern_matched}\t{self.pattern_category}"


class TypeAnnotator:
    """
    Lightweight entity type annotator using rule-based pattern matching.
    
    This class implements a comprehensive type annotation system that uses
    regex patterns and linguistic rules to assign semantic types to entities
    extracted from classical Chinese text. The system is designed to be
    fast, accurate, and easily extensible with new patterns.
    """
    
    def __init__(self, config_path: str = None, fuzzy_threshold: float = 0.8):
        """
        Initialize the TypeAnnotator with configurable patterns.
        
        Args:
            config_path (str, optional): Path to custom pattern configuration file.
                                       If None, uses default patterns optimized for
                                       classical Chinese literature.
            fuzzy_threshold (float): Threshold for fuzzy matching (0.0 to 1.0).
                                   Default is 0.8 for balanced accuracy.
        
        The annotator uses a hierarchical pattern matching system where
        high-confidence patterns are checked first, followed by medium and
        low confidence patterns. This ensures accurate type assignment while
        maintaining good coverage.
        """
        self.setup_logging()
        self.patterns = self._load_pattern_configuration(config_path)
        self.fuzzy_threshold = fuzzy_threshold
        self.statistics = {
            "total_entities": 0,
            "typed_entities": 0,
            "untyped_entities": 0,
            "type_distribution": defaultdict(int),
            "confidence_distribution": defaultdict(int),
            "pattern_usage": defaultdict(int)
        }
        
    def setup_logging(self):
        """
        Configure logging for detailed tracking of annotation process.
        
        This method sets up comprehensive logging to track the annotation process,
        including debug information about pattern matching and type assignments.
        """
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('logs/type_annotation.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # Create logs directory if it doesn't exist
        os.makedirs('logs', exist_ok=True)
    
    def _load_pattern_configuration(self, config_path: str = None) -> Dict[str, Dict]:
        """
        Load pattern configuration for entity type recognition.
        
        Args:
            config_path (str, optional): Path to custom configuration file
            
        Returns:
            Dict[str, Dict]: Dictionary containing patterns organized by type and confidence
            
        The pattern configuration includes regex patterns for different entity types,
        organized by confidence levels (high, medium, low) to optimize matching
        accuracy and performance.
        """
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        # Default pattern configuration optimized for classical Chinese literature
        return {
            "PERSON": {
                "high_confidence": [
                    # Dream of Red Chamber specific characters (highest priority)
                    (r'^(ÁîÑÂ£´Èö±|Ë≥àÈõ®Êùë|ÊûóÈªõÁéâ|Ë≥àÂØ∂Áéâ|ÁéãÁÜôÈ≥≥|ËñõÂØ∂Èáµ|Âè≤ÊπòÈõ≤|Ë≥àËøéÊò•|Ë≥àÊé¢Êò•|Ë≥àÊÉúÊò•|Â¶ôÁéâ|ÊùéÁ¥à|Áß¶ÂèØÂçø|Â∑ßÂßê|ÂäâÂß•Âß•|Ë≥àÊîø|ÁéãÂ§´‰∫∫|Ë≥àÊØç|ËñõÂß®Â™Ω|Ë∂ôÂß®Â®ò|Âë®ÁëûÂÆ∂ÁöÑ|‰æÜÊó∫ÂÆ∂ÁöÑ|Âê≥ËààÂÆ∂ÁöÑ|ÈÑ≠Â•ΩÊôÇ|Â§èÈáëÊ°Ç|Ë≥àÁèç|Ë≥àÁíâ|ËñõËü†|È¶ôËè±|Êô¥ÈõØ|Ë•≤‰∫∫|È¥õÈ¥¶|Âπ≥ÂÖí|Á¥´Èµë|Èõ™ÈõÅ|ÁßãÁ¥ã|Á¢ßÁóï|È∫ùÊúà|ËåúÈõ™|‰Ω≥Ëïô|ÂõõÂÖí|Ëä≥ÂÆò|ËïäÂÆò|ËóïÂÆò|Ë±ÜÂÆò|ËëµÂÆò|ËâæÂÆò|ÂØ∂ÂÆò|ÁéâÂÆò|ËåÑÂÆò|Ëó•ÂÆò|Â∞èÁ¥Ö|Â∞èËû∫|Âè∏Ê£ã|ÂæÖÊõ∏|Áπ°Ê©ò|ÂæÖÊúà|ÂΩ©Èúû|ÂΩ©Èõ≤|ÂΩ©È≥≥|ÁéâÈáßÂÖí|ÈáëÈáßÂÖí|È∂ØÂÖí|Áø†Â¢®|Áø†Á∏∑|Êô∫ËÉΩÂÖí|ÈáëÊ°Ç|ÂØ∂Ëüæ|È¶ôËè±|ÁîÑËã±ËìÆ|Â¨åÊùè|ÂÜ∑Â≠êËàà|Ë≥à‰ª£Âåñ|Ë≥à‰ª£ÂñÑ|Âè≤ËÄÅÂ§™Âêõ|ÁéãÂ≠êÈ®∞|Áéã‰ªÅ|ËñõÂß®Áàπ|ÂëÜÈú∏Áéã|Â§èÈáëÊ°Ç|ÁîÑÂØ∂Áéâ|ÂåóÈùúÁéã|Âø†È†ÜÁéãÁà∫|ÁîÑËÄÅÁà∫|ÁîÑÂ§™Â§™)$', 1.0, "hongloumeng_character"),
                    # Character titles and honorifics
                    (r'.*[ÂÖ¨Áéã‰æØ‰ºØÂ≠êÁî∑Áà∫Â®òÂ§´‰∫∫Â∞èÂßêÂÖ¨Â≠êÂ∞ëÁà∫ËÄÅÁà∫Â§™Â§™Â•∂Â•∂ÂßëÂ®ò‰∏´È†≠Êõ∏ÂÉÆÂ∞èÂªù]$', 0.9, "title_suffix"),
                    # Religious and mythological figures
                    (r'.*[‰ªôÂ≠êÁ•ûÂêõ‰ΩõÁ•ñËè©Ëñ©ÁæÖÊº¢Áúü‰∫∫ÈÅìÂ£´ÂíåÂ∞öÂ∞ºÂßë]$', 0.9, "religious_title"),
                    # Classical Chinese personal names with family names (more specific)
                    # Only match names that are clearly personal names, not locations or objects
                    (r'^(Ë≥à|Áéã|Êûó|Ëñõ|Âè≤|Êùé|Áß¶|Âäâ|Ë∂ô|Âë®|Âê≥|ÈÑ≠|È¶Æ|Èô≥|Ëî£|Ê≤à|Èüì|Ê•ä|Êú±|Â∞§|Ë®±|‰Ωï|ÂëÇ|ÊñΩ|Âºµ|Â≠î|Êõπ|Âö¥|ËèØ|Èáë|È≠è|Èô∂|Âßú|Êàö|Ë¨ù|ÈÑí|Âñª|Êüè|Ê∞¥|Á´á|Á´†|Èõ≤|Ëòá|ÊΩò|Ëëõ|Â•ö|ËåÉ|ÂΩ≠|ÈÉé|È≠Ø|Èüã|Êòå|È¶¨|Ëãó|È≥≥|Ëä±|Êñπ|‰øû|‰ªª|Ë¢Å|Êü≥|ÈÖÜ|ÈÆë|Âîê|Ë≤ª|Âªâ|Â≤ë|Èõ∑|Ë≥Ä|ÂÄ™|ÊπØ|Êªï|ÊÆ∑|ÁæÖ|Áï¢|ÈÉù|ÈÑî|ÂÆâ|Â∏∏|Ê®Ç|‰∫é|ÊôÇ|ÂÇÖ|ÁöÆ|Âçû|ÈΩä|Â∫∑|‰ºç|‰Ωô|ÂÖÉ|Âçú|È°ß|Â≠ü|Âπ≥|ÈªÉ|Âíå|Á©Ü|Ëï≠|Â∞π|Âßö|ÈÇµ|Êπõ|Ê±™|Á•Å|ÊØõ|Á¶π|ÁãÑ|Á±≥|Ë≤ù|Êòé|Ëáß|Ë®à|‰ºè|Êàê|Êà¥|Ë´á|ÂÆã|ËåÖ|Èæê|ÁÜä|Á¥Ä|Ëàí|Â±à|È†Ö|Á•ù|Ëë£|Ê¢Å|Êùú|ÈòÆ|Ëóç|Èñî|Â∏≠|Â≠£|È∫ª|Âº∑|Ë∑Ø|Â©Å|Âç±|Ê±ü|Á´•|È°è|ÈÉ≠|Ê¢Ö|Áõõ|ÂàÅ|Èçæ|Âæê|ÈÇ±|Èß±|È´ò|Â§è|Ëî°|Áî∞|Ê®ä|ËÉ°|Âáå|Èúç|Ëôû|Ëê¨|ÊîØ|ÊüØ|Êòù|ÁÆ°|Áõß|Ëé´|Á∂ì|Êàø|Ë£ò|ÁπÜ|Âπ≤|Ëß£|Êáâ|ÂÆó|‰∏Å|ÂÆ£|Ë≥Å|ÈÑß|È¨±|ÂñÆ|Êù≠|Ê¥™|ÂåÖ|Ë´∏|Â∑¶|Áü≥|Â¥î|Âêâ|Èàï|Èæî|Á®ã|Âµá|ÈÇ¢|Êªë|Ë£¥|Èô∏|Ê¶Æ|ÁøÅ|ËçÄ|Áæä|Êñº|ÊÉ†|ÁîÑ|Êõ≤|ÂÆ∂|Â∞Å|ËäÆ|Áæø|ÂÑ≤|Èù≥|Ê±≤|ÈÇ¥|Á≥ú|Êùæ|‰∫ï|ÊÆµ|ÂØå|Â∑´|ÁÉè|ÁÑ¶|Â∑¥|Âºì|Áâß|Èöó|Â±±|Ë∞∑|Ëªä|‰æØ|ÂÆì|Ëì¨|ÂÖ®|ÈÉó|Áè≠|‰ª∞|Áßã|‰ª≤|‰ºä|ÂÆÆ|ÂØß|‰ªá|Ê¨í|Êö¥|Áîò|Èàû|Âé≤|Êàé|Á•ñ|Ê≠¶|Á¨¶|Âäâ|ÊôØ|Ë©π|Êùü|Èæç|Ëëâ|Âπ∏|Âè∏|Èü∂|ÈÉú|Èªé|Ëñä|ËñÑ|Âç∞|ÂÆø|ÁôΩ|Êá∑|Ëí≤|ÈÇ∞|Âæû|ÈÑÇ|Á¥¢|Âí∏|Á±ç|Ë≥¥|Âçì|Ëó∫|Â±†|Ëíô|Ê±†|Âñ¨|Èô∞|È¨±|ËÉ•|ËÉΩ|Ëíº|Èõô|ËÅû|Ëéò|Èª®|Áøü|Ë≠ö|Ë≤¢|Âãû|ÈÄÑ|Âß¨|Áî≥|Êâ∂|Â†µ|ÂÜâ|ÂÆ∞|ÈÖà|Èõç|Âçª|Áí©|Ê°ë|Ê°Ç|ÊøÆ|Áâõ|Â£Ω|ÈÄö|ÈÇä|Êâà|Ááï|ÂÜÄ|ÈÉü|Êµ¶|Â∞ö|Ëæ≤|Ê∫´|Âà•|Ëéä|Êôè|Êü¥|Áûø|Èñª|ÂÖÖ|ÊÖï|ÈÄ£|Ëåπ|Áøí|ÂÆ¶|Ëâæ|È≠ö|ÂÆπ|Âêë|Âè§|Êòì|ÊÖé|Êàà|Âªñ|Â∫æ|ÁµÇ|Êö®|Â±Ö|Ë°°|Ê≠•|ÈÉΩ|ËÄø|Êªø|Âºò|Âå°|Âúã|Êñá|ÂØá|Âª£|Á•ø|Èóï|Êù±|Ê≠ê|ÊÆ≥|Ê≤É|Âà©|Ëîö|Ë∂ä|Â§î|ÈöÜ|Â∏´|Èûè|Âéô|ËÅ∂|ÊôÅ|Âãæ|Êïñ|Ëûç|ÂÜ∑|Ë®æ|Ëæõ|Èóû|ÈÇ£|Á∞°|È•í|Á©∫|Êõæ|ÊØã|Ê≤ô|‰πú|È§ä|Èû†|È†à|Ë±ê|Â∑¢|Èóú|ËíØ|Áõ∏|Êü•|Âæå|Ëçä|Á¥Ö|Ê∏∏|Á´∫|Ê¨ä|ÈÄØ|Ëìã|Âæå|Ê°ì|ÂÖ¨|‰∏á‰øü|Âè∏È¶¨|‰∏äÂÆò|Ê≠êÈôΩ|Â§è‰æØ|Ë´∏Ëëõ|ËÅû‰∫∫|Êù±Êñπ|Ëµ´ÈÄ£|ÁöáÁî´|Â∞âÈÅ≤|ÂÖ¨Áæä|ÊæπÂè∞|ÂÖ¨ÂÜ∂|ÂÆóÊîø|ÊøÆÈôΩ|Ê∑≥‰∫é|ÂñÆ‰∫é|Â§™Âèî|Áî≥Â±†|ÂÖ¨Â≠´|‰ª≤Â≠´|ËªíËΩÖ|‰ª§Áãê|ÈçæÈõ¢|ÂÆáÊñá|Èï∑Â≠´|ÊÖïÂÆπ|ÈÆÆ‰∫é|Èñ≠‰∏ò|Âè∏Âæí|Âè∏Á©∫|‰∏åÂÆò|Âè∏ÂØá|‰ªâÁù£|Â≠êËªä|È°ìÂ≠´|Á´ØÊú®|Â∑´È¶¨|ÂÖ¨Ë•ø|ÊºÜÈõï|Ê®ÇÊ≠£|Â£§Èßü|ÂÖ¨ËâØ|ÊãìË∑ã|Â§æË∞∑|ÂÆ∞Áà∂|Á©ÄÊ¢Å|ÊôâÊ•ö|ÈñÜÊ≥ï|Ê±ùÈÑ¢|Â°óÊ¨Ω|ÊÆµÂπ≤|ÁôæÈáå|Êù±ÈÉ≠|ÂçóÈñÄ|ÂëºÂª∂|Ê≠∏Êµ∑|ÁæäËàå|ÂæÆÁîü|Â∂ΩÂ∏•|Á∑±‰∫¢|Ê≥ÅÈÉà|ÊúâÁê¥|Ê¢Å‰∏ò|Â∑¶‰∏ò|Êù±ÈñÄ|Ë•øÈñÄ|ÂïÜÁâü|‰Ωò‰Ω¥|‰ºØË≥û|ÂçóÂÆÆ|Â¢®Âìà|Ë≠ôÁ¨™|Âπ¥ÊÑõ|ÈôΩ‰Ωü|Ë®ÄÁ¶è)[\u4e00-\u9fff]{1,2}$', 1.0, "chinese_full_name")
                ],
                "medium_confidence": [
                    # Names with common Chinese name characters
                    (r'[\u4e00-\u9fff]*[ÁéâÈõ≤Ê¢ÖËò≠ËèäÁ´πÊùæÈ≥≥ÈæçËôéË±πÈ∂¥Èµ¨ÈõÅÁáïÈ∂ØËù∂Ëä±ËçâÂ±±Ê∞¥Ê≤≥Êµ∑Â§©Âú∞Êó•ÊúàÊòüËæ∞Êò•Â§èÁßãÂÜ¨Èõ®Èõ™È¢®Èõ∑][\u4e00-\u9fff]*', 0.7, "poetic_name_elements"),
                    # Two or three character names
                    (r'^[\u4e00-\u9fff]{2,3}$', 0.6, "standard_name_length")
                ],
                "low_confidence": [
                    # Single character that could be a name
                    (r'^[\u4e00-\u9fff]$', 0.4, "single_character")
                ]
            },
            "LOCATION": {
                "high_confidence": [
                    # Geographical locations with clear indicators
                    (r'.*[Â±±Â∂∫Â≥∞Â∂ΩÂ≤≠Â≥ØÂ¥ñÂ¥ó‰∏òÈôµË∞∑Â∑ùÊ±üÊ≤≥ÊπñÊµ∑Ê¥ãÊ±†Â°òÊ∫™ÊæóÁÄëÊ≥â‰∫ï]$', 0.95, "geographical_suffix"),
                    (r'.*[ÂüéÂ∫úÂ∑ûÁ∏£ÈÉ°ÈéÆÊùëËéäÂØ®Â†°ÈóúÈñÄÊ®ìÈñ£ÊÆøÂ†ÇÂªüÂØ∫Èô¢ËßÄÂ°î‰∫≠Âè∞Ê¶≠ËªíÈΩãÊàøÂ±ãÂÆÖÈô¢ÂúíÊûó]$', 0.95, "architectural_suffix"),
                    # Direction-based locations
                    (r'.*[Êù±Ë•øÂçóÂåó‰∏≠‰∏ä‰∏ãÂâçÂæåÂ∑¶Âè≥ÂÖßÂ§ñ].*', 0.8, "directional_location"),
                    # Dream of Red Chamber specific locations
                    (r'^(Â§ßËçíÂ±±|ÁÑ°Á®ΩÂ¥ñ|ÈùíÂüÇÂ≥∞|Â§™ËôõÂπªÂ¢É|Èõ¢ÊÅ®Â§©|Ëµ§ÁëïÂÆÆ|Ë≠¶Âπª‰ªôÂ≠êÂÆÆ|Ë•øÊñπÈùàÊ≤≥Â≤∏|‰∏âÁîüÁü≥|ÂåóÈÇôÂ±±|ÂßëËòá|Èñ∂ÈñÄ|ÂçÅÈáåË°ó|‰ªÅÊ∏ÖÂ∑∑|Ëë´ËòÜÂªü|ËÉ°Â∑û|Á•û‰∫¨|Â§ßÂ¶ÇÂ∑û)$', 1.0, "hongloumeng_location")
                ],
                "medium_confidence": [
                    # Places with locative particles
                    (r'.*[‰πãÊñºÂú®].*', 0.6, "locative_particle"),
                    # Common place name patterns
                    (r'[\u4e00-\u9fff]*[Âú∞ÊñπËôïÊâÄÂ†¥Â†¥ÊâÄ]', 0.7, "place_indicator")
                ],
                "low_confidence": [
                    # Potentially geographical terms
                    (r'[\u4e00-\u9fff]*[Â¢ÉÁïåÂüüÂçÄ]', 0.5, "boundary_territory")
                ]
            },
            "CONCEPT": {
                "high_confidence": [
                    # Abstract philosophical concepts
                    (r'.*[ÈÅìÁêÜÁæ©Á¶Æ‰ªÅÊô∫‰ø°ÂãáÊÅïÂø†Â≠ùÊÇåÊÖàÊÑõÊÅ®ÊÉÖÊÖæÂøóÊ∞£Á•ûÈ≠ÇÈ≠ÑÈùàÂ§¢Âπª].*', 0.9, "philosophical_concept"),
                    # Emotional and psychological states
                    (r'.*[ÂñúÊÄíÂìÄÊ®ÇÊÑÅÊÜÇÊÄùÊÖÆÁñëÊáºÈ©öÊÅêÊÖöÊÑßÁæûËæ±Ê¶ÆËæ±ÂæóÂ§±ÊàêÊïóÁ¶çÁ¶èÂêâÂá∂].*', 0.85, "emotional_state"),
                    # Literary and narrative concepts
                    (r'.*[Âõ†ÊûúÁ∑£ÂàÜÂëΩÈÅãÂ§©ÊÑèÈÄ†ÂåñÁéÑÊ©üÂ•ßÁßòÁúüÂÅáËôõÂØ¶Â§¢ÈÜí].*', 0.9, "literary_concept")
                ],
                "medium_confidence": [
                    # General abstract nouns
                    (r'.*[‰∫ãÊÉÖ‰∫ãÁâ©ÁèæË±°ÁèæÂØ¶ÁúüÁõ∏ÈÅìÁêÜÂéüÂõ†ÁµêÊûúÁõÆÁöÑÊÑèÁæ©ÂÉπÂÄº‰ΩúÁî®ÂΩ±ÈüøÊïàÊûú].*', 0.7, "abstract_noun"),
                    # Social and cultural concepts
                    (r'.*[ÊñáÂåñÂÇ≥Áµ±Áøí‰øóÁ¶ÆÂÑÄÂà∂Â∫¶Ë¶èÁü©Ê≥ïÂâá].*', 0.75, "cultural_concept")
                ],
                "low_confidence": [
                    # Potentially abstract terms
                    (r'.*[ÊÄßË≥™ÁâπÈªûÁâπËâ≤ÁâπÂæµ].*', 0.5, "quality_trait")
                ]
            },
            "OBJECT": {
                "high_confidence": [
                    # Dream of Red Chamber specific objects (highest priority)
                    (r'^(ÈÄöÈùàÂØ∂Áéâ|Áü≥È†≠Ë®ò|Á¥ÖÊ®ìÂ§¢|ÊÉÖÂÉßÈåÑ|È¢®ÊúàÂØ∂Èëí|ÈáëÈôµÂçÅ‰∫åÈáµ|Â•Ω‰∫ÜÊ≠å)$', 1.0, "hongloumeng_object"),
                    # Specific objects and artifacts
                    (r'.*[ÁéâÁü≥Áè†ÂØ∂ÈáëÈäÄÈäÖÈêµÂô®ÂÖ∑Áî®ÂìÅÂ∑•ÂÖ∑Êõ∏Á±çÊñáÊàø].*', 0.9, "valuable_object"),
                    (r'.*[Ë°£ÊúçÂ∏ΩÂ≠êÈûãË•™È¶ñÈ£æË£ùÈ£æÂìÅ].*', 0.85, "clothing_accessory")
                ],
                "medium_confidence": [
                    # Common objects
                    (r'.*[Ê°åÊ§ÖÂ∫äÊ¶ªÂá†Ê°àÊ´ÉÁÆ±ÁõíÁì∂Â£∫Á¢óÁõ§].*', 0.75, "furniture_utensil"),
                    # Natural objects
                    (r'.*[Ëä±ËçâÊ®πÊú®ÊûúÂØ¶Á®ÆÂ≠êÊ†πËëâÊûùÂππ].*', 0.7, "natural_object")
                ],
                "low_confidence": [
                    # Generic object indicators
                    (r'.*[Áâ©ÂìÅÊù±Ë•ø].*', 0.5, "generic_object")
                ]
            },
            "ORGANIZATION": {
                "high_confidence": [
                    # Family and clan names
                    (r'.*[ÂÆ∂ÊóèÈñÄÁ¨¨‰∏ñÁ≥ªË°ÄËÑàÂÆóÊóè].*', 0.9, "family_organization"),
                    # Official and institutional terms
                    (r'.*[ÊúùÂª∑ÂÆòÂ∫úË°ôÈñÄÈÉ®ÈñÄÊ©üÊßãÁµÑÁπîÂúòÈ´î].*', 0.85, "official_organization")
                ],
                "medium_confidence": [
                    # Social groups
                    (r'.*[Áæ§ÁúæÁôæÂßìÊ∞ëÁúæ‰∫∫Ê∞ëÂ§ßÁúæ].*', 0.7, "social_group"),
                    # Professional groups
                    (r'.*[ÂïÜË≥àÂ∑•Âå†Ëæ≤Â§´Â≠∏ËÄÖÊñá‰∫∫].*', 0.75, "professional_group")
                ],
                "low_confidence": [
                    # Generic group terms
                    (r'.*[Áúæ‰∫∫Â§ßÂÆ∂].*', 0.5, "generic_group")
                ]
            },
            "EVENT": {
                "high_confidence": [
                    # Specific events and actions
                    (r'.*[Â©öÂ´ÅÂñ™Ëë¨Á•≠Á•ÄÊÖ∂ÂÖ∏ÂÑÄÂºè].*', 0.9, "ceremonial_event"),
                    # Historical events
                    (r'.*[Êà∞Áà≠Êà∞È¨•ÂæÅ‰ºêË®é‰ºêËµ∑Áæ©Âèõ‰∫ÇÈù©ÂëΩ].*', 0.85, "military_event")
                ],
                "medium_confidence": [
                    # General events and activities
                    (r'.*[ÊúÉË≠∞ËÅöÊúÉÈõÜÊúÉÂÆ¥ÊúÉÁ≠µÂ∏≠].*', 0.75, "social_event"),
                    # Natural events
                    (r'.*[ÁÅΩÈõ£ÁÅΩÂÆ≥Â§©ÁÅΩ‰∫∫Á¶ç].*', 0.7, "disaster_event")
                ],
                "low_confidence": [
                    # Generic event terms
                    (r'.*[‰∫ã‰ª∂‰∫ãÊÉÖ].*', 0.5, "generic_event")
                ]
            },
            "TEMPORAL": {
                "high_confidence": [
                    # Specific time periods
                    (r'.*[Êò•Â§èÁßãÂÜ¨Â≠£ÁØÄÂπ¥ÊúàÊó•ÊôÇËæ∞ÊúùÊöÆÊô®Êòè].*', 0.9, "time_period"),
                    # Dynasty and era names
                    (r'.*[Êúù‰ª£ÁéãÊúùÊôÇ‰ª£Âπ¥‰ª£‰∏ñ‰ª£].*', 0.85, "historical_period")
                ],
                "medium_confidence": [
                    # Time-related terms
                    (r'.*[ÊôÇÂÄôÊôÇÊ©üÊôÇÂàªÊôÇÈñì].*', 0.75, "time_related"),
                    # Sequential time
                    (r'.*[ÈÅéÂéªÁèæÂú®Â∞á‰æÜ‰ª•Ââç‰ª•ÂæåÂæûÂâçÂæÄÂæå].*', 0.7, "temporal_sequence")
                ],
                "low_confidence": [
                    # Generic temporal indicators
                    (r'.*[Áï∂ÊôÇÈÇ£ÊôÇÊ≠§ÊôÇ].*', 0.5, "temporal_indicator")
                ]
            }
        }
    
    def _match_patterns(self, entity: str, entity_type: str) -> Optional[EntityAnnotation]:
        """
        Match an entity against patterns for a specific type.
        
        Args:
            entity (str): Entity text to match
            entity_type (str): Type category to check patterns for
            
        Returns:
            Optional[EntityAnnotation]: Annotation if pattern matches, None otherwise
            
        This method checks an entity against all patterns for a given type,
        starting with high-confidence patterns and working down. The first
        matching pattern determines the annotation.
        """
        if entity_type not in self.patterns:
            return None
        
        # Check patterns in order of confidence: high -> medium -> low
        for confidence_level in ["high_confidence", "medium_confidence", "low_confidence"]:
            if confidence_level not in self.patterns[entity_type]:
                continue
                
            for pattern_data in self.patterns[entity_type][confidence_level]:
                pattern, confidence, pattern_name = pattern_data
                
                if re.search(pattern, entity):
                    self.statistics["pattern_usage"][f"{entity_type}_{pattern_name}"] += 1
                    
                    return EntityAnnotation(
                        entity=entity,
                        entity_type=entity_type,
                        confidence=confidence,
                        pattern_matched=pattern_name,
                        pattern_category=confidence_level
                    )
        
        return None
    
    def annotate_entity(self, entity: str) -> EntityAnnotation:
        """
        Annotate a single entity with its most likely type.
        
        Args:
            entity (str): Entity text to annotate
            
        Returns:
            EntityAnnotation: Annotation with type, confidence, and pattern info
            
        This method attempts to match the entity against all type patterns,
        selecting the match with the highest confidence score. If no patterns
        match, it assigns a default "UNKNOWN" type with low confidence.
        """
        entity = entity.strip()
        if not entity:
            # Update statistics for empty entity
            self.statistics["total_entities"] += 1
            self.statistics["untyped_entities"] += 1
            self.statistics["type_distribution"]["UNKNOWN"] += 1
            self.statistics["confidence_distribution"]["0-9%"] += 1
            
            return EntityAnnotation(
                entity=entity,
                entity_type="UNKNOWN",
                confidence=0.0,
                pattern_matched="empty_entity",
                pattern_category="none"
            )
        
        best_annotation = None
        best_confidence = 0.0
        
        # Try to match against all entity types in priority order
        # Check specific object types first, then PERSON for character names, then other types
        priority_order = ["OBJECT", "PERSON", "LOCATION", "CONCEPT", "ORGANIZATION", "EVENT", "TEMPORAL", "LITERARY"]
        
        for entity_type in priority_order:
            if entity_type in self.patterns:
                annotation = self._match_patterns(entity, entity_type)
                if annotation and annotation.confidence > best_confidence:
                    best_annotation = annotation
                    best_confidence = annotation.confidence
                    # If we found a high-confidence match (0.9+), use it immediately
                    if annotation.confidence >= 0.9:
                        break
        
        # If no pattern matched, assign UNKNOWN type
        if best_annotation is None:
            best_annotation = EntityAnnotation(
                entity=entity,
                entity_type="UNKNOWN",
                confidence=0.1,  # Low confidence for unknown entities
                pattern_matched="no_pattern_match",
                pattern_category="none"
            )
            self.statistics["untyped_entities"] += 1
        else:
            self.statistics["typed_entities"] += 1
        
        # Update statistics
        self.statistics["total_entities"] += 1
        self.statistics["type_distribution"][best_annotation.entity_type] += 1
        confidence_bucket = f"{int(best_annotation.confidence * 10) * 10}-{int(best_annotation.confidence * 10) * 10 + 9}%"
        self.statistics["confidence_distribution"][confidence_bucket] += 1
        
        return best_annotation
    
    def annotate_entity_list(self, entities: List[str]) -> List[EntityAnnotation]:
        """
        Annotate a list of entities with their types.
        
        Args:
            entities (List[str]): List of entity strings to annotate
            
        Returns:
            List[EntityAnnotation]: List of annotations for each entity
            
        This method processes a list of entities in batch, applying type
        annotation to each entity and returning a corresponding list of
        annotations.
        """
        annotations = []
        for entity in entities:
            if entity.strip():  # Skip empty entities
                annotation = self.annotate_entity(entity)
                annotations.append(annotation)
        
        return annotations
    
    def annotate_entities_file(self, input_path: str) -> List[List[EntityAnnotation]]:
        """
        Annotate entities from an entity file.
        
        Args:
            input_path (str): Path to input entity file
            
        Returns:
            List[List[EntityAnnotation]]: List of annotation lists, one per line
            
        This method reads an entity file and applies type annotation to all
        entities, preserving the line structure of the original file.
        """
        if not os.path.exists(input_path):
            raise FileNotFoundError(f"Input file not found: {input_path}")
        
        self.logger.info(f"Starting entity type annotation for file: {input_path}")
        
        annotated_lines = []
        
        try:
            with open(input_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            for line_num, line in enumerate(lines, 1):
                line = line.strip()
                if not line:
                    continue
                
                # Parse entities from line (assuming same format as clean_entities.py)
                entities = self._parse_entity_line(line)
                if entities:
                    annotations = self.annotate_entity_list(entities)
                    annotated_lines.append(annotations)
                    
                    self.logger.debug(f"Line {line_num}: Annotated {len(annotations)} entities")
            
            self.logger.info(f"Entity annotation completed. Processed {len(lines)} lines, "
                           f"annotated {self.statistics['total_entities']} entities")
            
        except Exception as e:
            self.logger.error(f"Error processing file {input_path}: {e}")
            raise
        
        return annotated_lines
    
    def _parse_entity_line(self, line: str) -> List[str]:
        """
        Parse a single entity line into a list of entities.
        
        Args:
            line (str): Raw entity line from the input file
            
        Returns:
            List[str]: List of individual entities
            
        This method reuses the parsing logic from clean_entities.py to handle
        the same input formats consistently.
        """
        line = line.strip()
        if not line:
            return []
        
        # Handle Python list format: ["entity1", "entity2"]
        if line.startswith('[') and line.endswith(']'):
            try:
                entities = eval(line)
                if isinstance(entities, list):
                    return [str(entity).strip() for entity in entities if str(entity).strip()]
            except (SyntaxError, ValueError):
                pass
        
        # Handle comma-separated format
        cleaned_line = re.sub(r'[\[\]"\'""''„Äå„Äç„Äé„Äè]', '', line)
        entities = [entity.strip() for entity in cleaned_line.split(',')]
        entities = [entity for entity in entities if entity]
        
        return entities
    
    def save_typed_entities(self, annotated_lines: List[List[EntityAnnotation]], 
                          output_path: str) -> None:
        """
        Save annotated entities to a TSV file.
        
        Args:
            annotated_lines (List[List[EntityAnnotation]]): Annotated entities
            output_path (str): Path for the output TSV file
            
        This method saves the annotated entities in TSV format with columns for
        entity text, type, confidence, matching pattern, and pattern category.
        The format is optimized for easy loading by downstream processing tools.
        """
        # Create output directory if it doesn't exist
        os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else '.', 
                   exist_ok=True)
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                # Write TSV header
                f.write("entity\ttype\tconfidence\tpattern\tcategory\n")
                
                # Write entity annotations
                for line_annotations in annotated_lines:
                    for annotation in line_annotations:
                        f.write(annotation.to_tsv_row() + '\n')
                    # Add empty line to separate original input lines
                    f.write('\n')
            
            self.logger.info(f"Typed entities saved to: {output_path}")
            
        except Exception as e:
            self.logger.error(f"Error saving typed entities to {output_path}: {e}")
            raise
    
    def get_annotation_statistics(self) -> Dict[str, Union[int, Dict]]:
        """
        Get comprehensive statistics about the annotation process.
        
        Returns:
            Dict: Dictionary containing detailed annotation statistics
            
        This method provides insights into the annotation process, including
        type distribution, confidence levels, and pattern usage statistics.
        """
        return {
            "total_entities": self.statistics["total_entities"],
            "typed_entities": self.statistics["typed_entities"],
            "untyped_entities": self.statistics["untyped_entities"],
            "typing_rate": self.statistics["typed_entities"] / max(1, self.statistics["total_entities"]),
            "type_distribution": dict(self.statistics["type_distribution"]),
            "confidence_distribution": dict(self.statistics["confidence_distribution"]),
            "pattern_usage": dict(self.statistics["pattern_usage"])
        }
    
    def print_statistics(self) -> None:
        """
        Print a formatted summary of annotation statistics.
        
        This method provides a human-readable summary of the annotation process,
        including type distribution, confidence metrics, and pattern effectiveness.
        """
        stats = self.get_annotation_statistics()
        
        print("\n" + "="*60)
        print("ENTITY TYPE ANNOTATION STATISTICS")
        print("="*60)
        print(f"Total entities processed: {stats['total_entities']}")
        print(f"Successfully typed: {stats['typed_entities']}")
        print(f"Untyped (UNKNOWN): {stats['untyped_entities']}")
        print(f"Typing success rate: {stats['typing_rate']:.1%}")
        
        print("\nType Distribution:")
        print("-" * 30)
        for entity_type, count in sorted(stats['type_distribution'].items(), key=lambda x: x[1], reverse=True):
            percentage = count / stats['total_entities'] * 100
            print(f"  {entity_type:<15}: {count:>4} ({percentage:>5.1f}%)")
        
        print("\nConfidence Distribution:")
        print("-" * 30)
        for conf_range, count in sorted(stats['confidence_distribution'].items()):
            percentage = count / stats['total_entities'] * 100
            print(f"  {conf_range:<15}: {count:>4} ({percentage:>5.1f}%)")
        
        print("\nTop Pattern Usage:")
        print("-" * 30)
        top_patterns = sorted(stats['pattern_usage'].items(), key=lambda x: x[1], reverse=True)[:10]
        for pattern, count in top_patterns:
            print(f"  {pattern:<30}: {count:>4}")
        
        print("="*60)


def main():
    """
    Command-line interface for the type annotator.
    
    This function provides a convenient command-line interface for running
    the entity type annotation process with customizable parameters.
    """
    parser = argparse.ArgumentParser(
        description="Annotate entities with semantic types using rule-based patterns",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python type_annotator.py --input test_entity.txt --output test_entity_typed.tsv
  python type_annotator.py --input data/entities.txt --config custom_patterns.json --verbose
        """
    )
    
    parser.add_argument(
        '--input', '-i',
        required=True,
        help='Input entity file path'
    )
    
    parser.add_argument(
        '--output', '-o',
        required=True,
        help='Output typed entity TSV file path'
    )
    
    parser.add_argument(
        '--config', '-c',
        help='Custom pattern configuration file path'
    )
    
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='Enable verbose logging'
    )
    
    args = parser.parse_args()
    
    # Set logging level based on verbose flag
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    try:
        # Initialize annotator with optional custom configuration
        annotator = TypeAnnotator(config_path=args.config)
        
        # Annotate entities from file
        annotated_entities = annotator.annotate_entities_file(args.input)
        
        # Save typed entities
        annotator.save_typed_entities(annotated_entities, args.output)
        
        # Print statistics
        annotator.print_statistics()
        
        print(f"\n‚úÖ Entity type annotation completed successfully!")
        print(f"üìÑ Input: {args.input}")
        print(f"üìÑ Output: {args.output}")
        print(f"üìä Format: TSV with type annotations")
        
    except Exception as e:
        print(f"‚ùå Error during entity type annotation: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
