### 2025/9/10
1. Although today try to use more strict and practicle process to debug, the error of the cli still happening again.(Maybe is the original code quality is not well, spending lots of time on the debugging and AI Coding made the codes more complicated.) Like below:
```
 GPT-5-mini ECTD pipeline completed successfully for Iteration 3!        
ğŸ“‚ Results available in: d:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\datasets\KIMI_result_DreamOf_RedChamber\Graph_Iteration3
ğŸ”„ You can now run the next iteration or proceed to semantic graph generation.
[SUCCESS] Pipeline execution completed successfully!
[LOG] Terminal progress log saved to: ..\docs\Iteration_Terminal_Progress\gpt5mini_entity_iteration_20250910_215621.txt
ğŸ” Checking location: d:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\datasets\KIMI_result_DreamOf_RedChamber\Graph_Iteration3
   âœ— test_entity.txt (missing, 0 bytes)
   âœ— test_denoised.target (missing, 0 bytes)
ğŸ” Checking location: d:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\chat\datasets\KIMI_result_DreamOf_RedChamber\Graph_Iteration3
   âœ— test_entity.txt (missing, 0 bytes)
   âœ— test_denoised.target (missing, 0 bytes)
ğŸ” Checking location: d:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\docs\Iteration_Report\Iteration3\results\ectd
   âœ— test_entity.txt (missing, 0 bytes)
   âœ— test_denoised.target (missing, 0 bytes)
âŒ Output files not found in any checked locations:
   Actual: d:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\datasets\KIMI_result_DreamOf_RedChamber\Graph_Iteration3
   Primary: d:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\chat\datasets\KIMI_result_DreamOf_RedChamber\Graph_Iteration3
   Legacy: d:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\docs\Iteration_Report\Iteration3\results\ectd
   Note: Files must exist AND have non-zero size

 ECTD stage completed but missing expected output files!
ECTD stage failed after 526.6s
âŒ ECTD failed: Missing expected output files

âŒ Pipeline failed at stage: ectd

============================================================
âŒ PIPELINE FAILED
ğŸ“ Failed at stage: ectd
ğŸ”„ To resume: use --start-from-stage ectd
============================================================
```
So, for the sake of just combine function of the `run_entity.py` and `run_triple.py` and `run_gj.py` to be a pipeline, tentively abandon the cli plan. Change to the streamlit plan, change to use streamlit to implement this function will be more smoothly to accomplish AI Function.

---

### 2025/9/12

- Claude code is a good ai coding agent, better than the cursor and github copilot, but it limit 45-50 times of conversationing to ai, so it's necessary to write the detail spec.md and Task.md during developing and when ask you to commmand , need to choose "no ask, auto run" to save the 5 hour 45-50 times conversation credits. 

- And I spend too much credit in the morning to solve the problem that Claude code editted contents wouldn't save to the file. The solution is here, when the first time to use Claude Code, can following below to prevent the same problem :
1) lower the Claude Code edition and update to the latest edition:
   ```bash
   # Completely delete the Claude Code (if already installed)
   npm uninstall -g @anthropic-ai/claude-code

   # install the `1.0.77` edition
   npm install -g @anthropic-ai/claude-code@1.0.77 --save-exact

   # Then update to the latest
   npm install -g @anthropic-ai/claude-code@lates

   ```
2) Ensure not install the extention `Prettier`.
3) Add the two lines below in the heading of `Claude.md`(This file need to set in the Claude Code initially, and it will in your project root folder.):
   - Verify the file status before editing.
   - If encountering storage issues, please reload the file.
4) The permission setting
   - Open the Claude Code.
   - Enter `/permissions`
   - Choose `Allow`
   - Enter the lines below to add the instruction:
     ```
     Always allow "Edit" tool
     Always allow "CreateFile" tool
     ```
5) Test the result
   In claude code enter : "è«‹å¹«æˆ‘åŠ å…¥ç·¨è¼¯ test.js æª”æ¡ˆï¼ŒåŠ å…¥ä¸€è¡Œè¨»è§£"ã€‚ If succeed, the file will show in the root folder.
6) Appendix : If still failed
   - Use VS Code in the command enter : `code %USERPROFILE%\.claude\settings.json`
   - Adding the below to the json file:
   ```
   {
     "allowedTools": {
       "Edit": "always",
       "CreateFile": "always",
       "ReadFile": "always"
      },
     "autoApprove": {
       "edit": true,
       "bash": ["git commit", "git add", "npm install"]
      }
   }

   ```

### 2025/9/14

#### streamlit_pipeline graphjudge æ”¹é€²é»

1) ä»‹é¢éœ€è¦ç‚ºè‹±æ–‡ ok
2) è¼¸å…¥æ–‡å­—è«‹æ”¹ç‚ºbrowseæ–‡ä»¶çš„(txt file) ok
3) ok - when click "api connection check" button, it will show the bug of :
```
Application error occurred

StreamlitAPIException: Method spinner() does not exist for st.sidebar. Did you mean st.spinner()?

Traceback:
File "D:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\streamlit_pipeline\app.py", line 160, in run
    self._render_sidebar()
File "D:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\streamlit_pipeline\app.py", line 233, in _render_sidebar
    with st.sidebar.spinner("æµ‹è¯•ä¸­..."):
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
File "D:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\streamlit_pipeline\.venv\Lib\site-packages\streamlit\delta_generator.py", line 373, in wrapper
    raise StreamlitAPIException(message)
    
and

Failed to initialize application

AttributeError: 'StreamlitLogger' object has no attribute 'log_error'
Traceback:
File "D:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\streamlit_pipeline\app.py", line 533, in main
    app.run()
File "D:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\streamlit_pipeline\app.py", line 177, in run
    st.session_state.logger.log_error(
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

```

---

4) OK when texts entered and click start processing button, shows the error below :

```
Processing failed: 'StreamlitLogger' object has no attribute 'log_info'

Application error occurred

TypeError: ErrorInfo.__init__() missing 1 required positional argument: 'severity'
Traceback:
File "D:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\streamlit_pipeline\app.py", line 166, in run
    self._render_main_interface()
File "D:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\streamlit_pipeline\app.py", line 323, in _render_main_interface
    self._start_processing(input_text.strip())
File "D:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\streamlit_pipeline\app.py", line 429, in _start_processing
    error_info = ErrorInfo(
                 ^^^^^^^^^^

```

and 

```
Failed to initialize application

AttributeError: 'StreamlitLogger' object has no attribute 'log_error'
Traceback:
File "D:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\streamlit_pipeline\app.py", line 533, in main
    app.run()
File "D:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\streamlit_pipeline\app.py", line 177, in run
    st.session_state.logger.log_error(
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
```

---

5) ok - The pipeline successfully completes entity extraction and finds entities in the input text, but when it proceeds to the triple generation stage, no triples are generated from these extracted entities.

The system displays the error message "Pipeline failed at stage: triple_generation" followed by "Error: No triples were generated from the extracted entities" even though entities were successfully found in the previous stage.

The extracted entities are not being saved to the project folder as expected, and there is suspicion that the denoised text processing step in the ECTD (Entity Extraction, Cleaning, Text Denoising) phase may not be functioning properly.

   - Streamlit output: [in "streamlit_pipeline" folder, when running to the triple generation(entity extraction complete),
  occured the problem below :
  Pipeline failed at stage: triple_generation. Error: No triples were generated from the extracted entities]
  
6) ok - please show more processing éç¨‹ in the streamlit_pipeline , more detail process in every phase, like the original source code.
  
7) ok - and there's no log saved in the project folder 
  
8) ok - need to edit the denoised texts prompt into the :
   
```
  ç›®æ¨™ï¼š
åŸºæ–¼çµ¦å®šçš„å¯¦é«”ï¼Œå°å¤å…¸ä¸­æ–‡æ–‡æœ¬é€²è¡Œå»å™ªè™•ç†ï¼Œå³ç§»é™¤ç„¡é—œçš„æè¿°æ€§æ–‡å­—ä¸¦é‡çµ„ç‚ºæ¸…æ™°çš„äº‹å¯¦é™³è¿°ã€‚

ä»¥ä¸‹æ˜¯ã€Šç´…æ¨“å¤¢ã€‹çš„ä¸‰å€‹ç¯„ä¾‹ï¼š
ç¯„ä¾‹#1:
åŸå§‹æ–‡æœ¬ï¼š"å»Ÿæ—ä½è‘—ä¸€å®¶é„‰å®¦ï¼Œå§“ç”„ï¼Œåè²»ï¼Œå­—å£«éš±ã€‚å«¡å¦»å°æ°ï¼Œæƒ…æ€§è³¢æ·‘ï¼Œæ·±æ˜ç¦®ç¾©ã€‚å®¶ä¸­é›–ä¸ç”šå¯Œè²´ï¼Œç„¶æœ¬åœ°ä¾¿ä¹Ÿæ¨ä»–ç‚ºæœ›æ—äº†ã€‚"
å¯¦é«”ï¼š["ç”„è²»", "ç”„å£«éš±", "å°æ°", "é„‰å®¦"]
å»å™ªæ–‡æœ¬ï¼š"ç”„å£«éš±æ˜¯ä¸€å®¶é„‰å®¦ã€‚ç”„å£«éš±å§“ç”„åè²»å­—å£«éš±ã€‚ç”„å£«éš±çš„å¦»å­æ˜¯å°æ°ã€‚å°æ°æƒ…æ€§è³¢æ·‘æ·±æ˜ç¦®ç¾©ã€‚ç”„å®¶æ˜¯æœ¬åœ°æœ›æ—ã€‚"

ç¯„ä¾‹#2:
åŸå§‹æ–‡æœ¬ï¼š"è³ˆé›¨æ‘åŸç³»èƒ¡å·äººæ°ï¼Œä¹Ÿæ˜¯è©©æ›¸ä»•å®¦ä¹‹æ—ï¼Œå› ä»–ç”Ÿæ–¼æœ«ä¸–ï¼Œçˆ¶æ¯ç¥–å®—æ ¹åŸºå·²ç›¡ï¼Œäººå£è¡°å–ªï¼Œåªå‰©å¾—ä»–ä¸€èº«ä¸€å£ï¼Œåœ¨å®¶é„‰ç„¡ç›Šï¼Œå› é€²äº¬æ±‚å–åŠŸåï¼Œå†æ•´åŸºæ¥­ã€‚"
å¯¦é«”ï¼š["è³ˆé›¨æ‘", "èƒ¡å·", "è©©æ›¸ä»•å®¦ä¹‹æ—"]
å»å™ªæ–‡æœ¬ï¼š"è³ˆé›¨æ‘æ˜¯èƒ¡å·äººæ°ã€‚è³ˆé›¨æ‘æ˜¯è©©æ›¸ä»•å®¦ä¹‹æ—ã€‚è³ˆé›¨æ‘ç”Ÿæ–¼æœ«ä¸–ã€‚è³ˆé›¨æ‘çˆ¶æ¯ç¥–å®—æ ¹åŸºå·²ç›¡ã€‚è³ˆé›¨æ‘é€²äº¬æ±‚å–åŠŸåã€‚è³ˆé›¨æ‘æƒ³è¦é‡æ•´åŸºæ¥­ã€‚"

ç¯„ä¾‹#3:
åŸå§‹æ–‡æœ¬ï¼š"è³ˆå¯¶ç‰å› å¤¢éŠå¤ªè™›å¹»å¢ƒï¼Œé “ç”Ÿç–‘æ‡¼ï¼Œé†’ä¾†å¾Œå¿ƒä¸­ä¸å®‰ï¼Œé‚å°‡æ­¤äº‹å‘ŠçŸ¥æ—é»›ç‰ï¼Œé»›ç‰è½å¾Œäº¦æ„Ÿé©šç•°ã€‚"
å¯¦é«”ï¼š["è³ˆå¯¶ç‰", "å¤ªè™›å¹»å¢ƒ", "æ—é»›ç‰"]
å»å™ªæ–‡æœ¬ï¼š"è³ˆå¯¶ç‰å¤¢éŠå¤ªè™›å¹»å¢ƒã€‚è³ˆå¯¶ç‰å¤¢é†’å¾Œé “ç”Ÿç–‘æ‡¼ã€‚è³ˆå¯¶ç‰å°‡æ­¤äº‹å‘ŠçŸ¥æ—é»›ç‰ã€‚æ—é»›ç‰è½å¾Œæ„Ÿåˆ°é©šç•°ã€‚"

è«‹åƒè€ƒä»¥ä¸Šç¯„ä¾‹ï¼Œè™•ç†ä»¥ä¸‹æ–‡æœ¬ï¼š
åŸå§‹æ–‡æœ¬ï¼š{t}
å¯¦é«”ï¼š{entities}
å»å™ªæ–‡æœ¬ï¼š"""
```
  
9) [Unnecessary - the process can look at terminal] You pretend as a user, definitely want to see more actual processing in streamlit ui, if can show the process of the every phase processing. e.g. in the entity extract phase  need to show 1/27 entites or in the in the triple phase need to show the 1/27 triples ..., and so on on the graph judge.

10) ok- please read "chat\run_gj.py" and "chat\convert_Judge_To_jsonGraph.py" to parse to the proper graph json file(as the source code demanded format). And  show the graph in streamlit "Relationship Network Graph" (Now, it's only showed : Network graph requires Plotly library: pip install plotly

Text-based relationship display:
1. å¥³åª§æ° â†’ åœ°é» â†’ å¤§è’å±±
2. å¥³åª§æ° â†’ åœ°é» â†’ ç„¡ç¨½å´–
3. çŸ³é ­ â†’ åœ°é» â†’ é’åŸ‚å³°
...)

11) ok - the bug occured : 

```
"Application error occurred

StreamlitAPIException: Expanders may not be nested inside other expanders.

Traceback:
File "D:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\streamlit_pipeline\app.py", line 171, in run
    self._render_main_interface()
File "D:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\streamlit_pipeline\app.py", line 349, in _render_main_interface
    self._render_results_section(st.session_state.current_result)
File "D:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\streamlit_pipeline\app.py", line 551, in _render_results_section
    display_triple_results(result.triple_result)
File "D:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\streamlit_pipeline\ui\components.py", line 398, in display_triple_results
    with st.expander("ğŸ”¬ Detailed Triple Generation Phases", expanded=True):
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
File "C:\Users\USER\AppData\Local\Programs\Python\Python312\Lib\site-packages\streamlit\runtime\metrics_util.py", line 410, in wrapped_func
    result = non_optional_func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
File "C:\Users\USER\AppData\Local\Programs\Python\Python312\Lib\site-packages\streamlit\elements\layouts.py", line 601, in expander
    return self.dg._block(block_proto=block_proto)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
File "C:\Users\USER\AppData\Local\Programs\Python\Python312\Lib\site-packages\streamlit\delta_generator.py", line 518, in _block
    _check_nested_element_violation(self, block_type, ancestor_block_types)
File "C:\Users\USER\AppData\Local\Programs\Python\Python312\Lib\site-packages\streamlit\delta_generator.py", line 598, in _check_nested_element_violation
    raise StreamlitAPIException("
```

---

#### Claude Code Development improvement skill

1) [In this video](https://www.youtube.com/watch?v=amEUIuBKwvg&t=2558s&ab_channel=ColeMedin&loop=0)
   - add primer.md in the project
   - Add the MCP Serena Sever in Claude code
   - (continue video...)

---

### 2025/9/17

To do :

1) ok edit the prompt of `streamlit_pipeline\core\triple_generator.py` to the below:

```

return f"""
Task: Analyze a text written in Classical Chinese, Modern Chinese (Traditional), or English to extract semantic relations between entities, and output standard JSON triples.

Supported languages: Classical Chinese (å¤æ¼¢èª), Modern Chinese (ç¹é«”ä¸­æ–‡ç™½è©±æ–‡), English.

Output format:
```
{
  "triples": [
    ["ä¸»é«”", "é—œä¿‚", "å®¢é«”"],
    ["ä¸»é«”", "é—œä¿‚", "å®¢é«”"]
  ]
}
```

Relation label guidelines:
- Use concise Chinese relation labels (e.g., "è·æ¥­", "å¦»å­", "åœ°é»", "è¡Œç‚º").
- Avoid verbose descriptions or explanatory phrases.
- Ensure each relation has a clear, specific semantic meaning.
- Prefer common, standard relation types.

Extraction principles:
1. Focus on entities in the provided entity list.
2. Extract only relations explicitly stated in the text.
3. Do not infer or speculate implicit relations.
4. Every triple must be directly supported by the source text.

Language-specific instructions:
- Classical Chinese: Handle ellipsis and classical syntax. If the subject is omitted but unambiguous within the sentence, you may recover it; otherwise, skip. Keep entities exactly as written.
- Modern Chinese (Traditional): Follow punctuation and context; keep entities exactly as written.
- English: Keep entities exactly as written in English. Relation labels must still be in Chinese.
- Do not translate or romanize entities. Do not translate relation labels.

Examples:

Classical Chinese:
Input text: "å¤ªå²å…¬æ›°ï¼šå­”å­å¸ƒè¡£ï¼Œå‚³åé¤˜ä¸–ï¼Œå­¸åœ¨å®˜åºœã€‚å¼Ÿå­å……æ–¼å¤©ä¸‹ï¼Œä½•å…¶ç››ä¹Ÿï¼"
Entity list: ["å­”å­", "å¸ƒè¡£", "å­¸", "å®˜åºœ", "å¼Ÿå­", "å¤©ä¸‹"]
Output:
```
{
  "triples": [
    ["å­”å­", "èº«åˆ†", "å¸ƒè¡£"],
    ["å­¸", "åœ°é»", "å®˜åºœ"],
    ["å¼Ÿå­", "åœ°é»", "å¤©ä¸‹"]
  ]
}
```

Modern Chinese (Traditional):
Input text: "ç”„å£«éš±æ˜¯å§‘è˜‡åŸå…§çš„é„‰å®¦ï¼Œå¦»å­æ˜¯å°æ°ï¼Œæœ‰ä¸€å¥³åè‹±è“®ã€‚"
Entity list: ["ç”„å£«éš±", "å§‘è˜‡åŸ", "é„‰å®¦", "å°æ°", "è‹±è“®"]
Output:
```
{
  "triples": [
    ["ç”„å£«éš±", "åœ°é»", "å§‘è˜‡åŸ"],
    ["ç”„å£«éš±", "è·æ¥­", "é„‰å®¦"],
    ["ç”„å£«éš±", "å¦»å­", "å°æ°"],
    ["ç”„å£«éš±", "å¥³å…’", "è‹±è“®"]
  ]
}
```

English:
Input text: "Socrates was a philosopher in Athens. His wife was Xanthippe."
Entity list: ["Socrates", "Athens", "philosopher", "Xanthippe"]
Output:
```
{
  "triples": [
    ["Socrates", "profession", "philosopher"],
    ["Socrates", "location", "Athens"],
    ["Socrates", "wife", "Xanthippe"]
  ]
}
```

Current task:
Text: {text_content}
Entity list: {entity_str}
Return only the JSON in the specified format.
"""

```

2) [Cancel - becuase need to concentrate on the ancient chinese text processing.] edit the prompt of `streamlit_pipeline\core\graph_judge.py` to fit the ancient chinese, modern chinese, and the english needs, not just ancient chinese.

3) the above finished, can fork the original GraphJudge repo again, and upload the streamlit clean code to others people to use. 

---

ok - To do :
fix the bug below , when the ectd finished:

```
[INFO] [INFO] [API] Making API call for chunk 1 with system prompt
23:13:33 - LiteLLM:INFO: utils.py:3119 -
LiteLLM completion() model= gpt-5-mini; provider = openai
INFO:LiteLLM:
LiteLLM completion() model= gpt-5-mini; provider = openai
INFO:openai._base_client:Retrying request to /chat/completions in 0.454055 seconds
INFO:openai._base_client:Retrying request to /chat/completions in 0.984037 seconds

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

23:16:35 - LiteLLM:INFO: utils.py:3119 - 
LiteLLM completion() model= gpt-5-mini; provider = openai
INFO:LiteLLM:
LiteLLM completion() model= gpt-5-mini; provider = openai
INFO:openai._base_client:Retrying request to /chat/completions in 0.455126 seconds
INFO:openai._base_client:Retrying request to /chat/completions in 0.927726 seconds

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

23:19:38 - LiteLLM:INFO: utils.py:3119 - 
LiteLLM completion() model= gpt-5-mini; provider = openai
INFO:LiteLLM:
LiteLLM completion() model= gpt-5-mini; provider = openai
INFO:openai._base_client:Retrying request to /chat/completions in 0.395935 seconds
INFO:openai._base_client:Retrying request to /chat/completions in 0.935379 seconds

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

[WARN] [WARNING] [API] API call failed, continuing without response: API call failed after 3 attempts: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out.
DEBUG API RESPONSE: Empty or None response received for chunk 1!
DEBUG: Response type: <class 'NoneType'>
DEBUG: Response repr: None
[ERROR] [ERROR] [API] Empty response received from GPT-5-mini
[DEBUG] [DEBUG] [TRIPLE] Received API response for chunk
[DEBUG] [DEBUG] [TRIPLE] Validating response schema
[WARN] [WARNING] [TRIPLE] Schema validation failed for chunk 1
[DEBUG] [DEBUG] [TRIPLE] Starting triple deduplication
[INFO] [INFO] [TRIPLE] Triple deduplication completed
[DEBUG] [DEBUG] [TRIPLE] Prepared extraction metadata
[INFO] [INFO] [TRIPLE] Triple generation analysis
[ERROR] [ERROR] [TRIPLE] Triple generation failed: no triples generated
[ERROR] [ERROR] [TRIPLE] Triple generation failed
INFO:streamlit_pipeline.utils.session_state:Pipeline result stored. Run #1, Success: False
INFO:streamlit_pipeline.utils.session_state:Processing completed/stopped
[INFO] [INFO] Logger initialized for phase: pipeline
[INFO] [INFO] Log files created in: D:\AboutCoding\AI_Research\GraphJudge_TextToKG_CLI\streamlit_pipeline\logs\2025_09_17\pipeline
INFO:streamlit_pipeline.utils.state_cleanup:Automatic cleanup scheduled every 30 minutes
```
streamlit ui :
Pipeline failed at stage: triple_generation

Error: No triples were generated from the provided entities and text

---

### 2025/9/18

- to do 
1) Add the streamlit ui language selection in the streamlit ui : English/ç¹é«”ä¸­æ–‡/ç°¡é«”ä¸­æ–‡. And set the default language in English. Remeber, this system is focus on the ancient chinese text processing.
   --> the remaining texts that after the "Final Results" in the streamlit ui doesn't match the language setting. As you are a professional engineer, please overview the streamlit_pipeline project, and edit all the language showing in the streamlit ui need to set in the language setting. 
2) ok - ensure the explanination function worked in the streamlit_pipeline.
3) ok - Acutal smoke test the latest edit.
4) figure out how the confidence calculated.
5) And it seemed that the perplexity judgement explaniations are not saved in the folder as the actual file.