# GraphJudge Phase Modular Test Suite

## ðŸ“‹ Overview

This is the complete test suite for the GraphJudge Phase modular system, ensuring full compatibility with the original `run_gj.py` functionality while testing each component of the modular architecture.

## ðŸ—ï¸ Test Structure

### Test Module Organization

tests/
â”œâ”€â”€ init.py # Test suite initialization
â”œâ”€â”€ conftest.py # Shared test configuration and fixtures
â”œâ”€â”€ test_config.py # Configuration module tests
â”œâ”€â”€ test_data_structures.py # Data structures tests
â”œâ”€â”€ test_graph_judge_core.py # Core judgment logic tests
â”œâ”€â”€ test_prompt_engineering.py # Prompt engineering tests
â”œâ”€â”€ test_gold_label_bootstrapping.py # Gold label bootstrapping tests
â”œâ”€â”€ test_utilities.py # Utility functions tests
â”œâ”€â”€ test_processing_pipeline.py # Processing pipeline tests
â”œâ”€â”€ test_integration.py # Integration tests
â”œâ”€â”€ run_tests.py # Test runner
â””â”€â”€ README.md # This document


## ðŸ“Š Test Coverage

### Correspondence to original `test_run_gj.py`

| Original Test Class               | Corresponding Modular Test           | Test File                             |
|-----------------------------------|--------------------------------------|---------------------------------------|
| `TestPerplexityGraphJudge`        | Core judgment functionality tests    | `test_graph_judge_core.py`            |
| `TestPerplexityCompletion`        | Processing pipeline tests            | `test_processing_pipeline.py`         |
| `TestInputValidation`             | Input validation tests               | `test_utilities.py`                   |
| `TestExplainableOutputHandling`   | Explainable output tests             | `test_prompt_engineering.py`          |
| `TestResponseProcessing`          | Response handling tests              | `test_processing_pipeline.py`         |
| `TestErrorHandling`               | Error handling tests                 | `test_integration.py`                 |
| `TestIntegration`                 | Integration tests                    | `test_integration.py`                 |
| Gold label bootstrapping tests    | Bootstrapping system tests           | `test_gold_label_bootstrapping.py`    |

### Test Feature Completeness

#### âœ… Core Functionality Tests (`test_graph_judge_core.py`)
- âœ… PerplexityGraphJudge initialization  
- âœ… Basic graph judgment (mock and real modes)  
- âœ… Explainable judgment  
- âœ… Streaming judgment  
- âœ… Citation handling  
- âœ… Error handling and retry logic  
- âœ… Compatibility across judgment modes  

#### âœ… Prompt Engineering Tests (`test_prompt_engineering.py`)
- âœ… Basic judgment prompt creation  
- âœ… Explainable judgment prompt creation  
- âœ… Response parsing (Yes/No classification)  
- âœ… Explainable response parsing  
- âœ… Citation extraction and handling  
- âœ… HTML cleaning and text processing  
- âœ… Multilingual content handling  

#### âœ… Gold Label Bootstrapping Tests (`test_gold_label_bootstrapping.py`)
- âœ… Triple data loading  
- âœ… Source text processing  
- âœ… Stage 1: RapidFuzz string matching  
- âœ… Stage 2: LLM semantic evaluation  
- âœ… Sampling uncertain cases  
- âœ… Result saving and statistics  
- âœ… Full bootstrapping workflow  

#### âœ… Processing Pipeline Tests (`test_processing_pipeline.py`)
- âœ… Standard processing mode  
- âœ… Explainable processing mode  
- âœ… Concurrency control and rate limiting  
- âœ… Statistics calculation  
- âœ… File operations (CSV and JSON)  
- âœ… Error handling  

#### âœ… Data Structures Tests (`test_data_structures.py`)
- âœ… `TripleData` structure  
- âœ… `BootstrapResult` structure  
- âœ… `ExplainableJudgment` structure  
- âœ… Citation-related structures  
- âœ… Processing and statistics structures  
- âœ… JSON serialization compatibility  

#### âœ… Utilities Tests (`test_utilities.py`)
- âœ… File validation  
- âœ… Directory operations  
- âœ… Environment validation  
- âœ… Instruction format validation  
- âœ… Text processing  
- âœ… File operations  
- âœ… System utilities  

#### âœ… Configuration Tests (`test_config.py`)
- âœ… Configuration constants validation  
- âœ… Environment variable handling  
- âœ… File path generation  
- âœ… Pipeline integration  

#### âœ… Integration Tests (`test_integration.py`)
- âœ… Module-to-module integration  
- âœ… End-to-end workflows  
- âœ… Compatibility with original functionality  
- âœ… Error handling integration  
- âœ… Performance tests  
- âœ… Cross-module data flow  

## ðŸš€ Running the Tests

### Basic Usage

```bash
# Run all tests
python tests/run_tests.py

# Verbose output
python tests/run_tests.py -v

# Include coverage report
python tests/run_tests.py --coverage

# Run a specific test file
python tests/run_tests.py -t test_config.py

# Verbose + coverage
python tests/run_tests.py -v --coverage
```

### Using pytest Directly

```bash
# Run all tests
pytest tests/ -v

# Run a specific test
pytest tests/test_graph_judge_core.py -v

# Include coverage
pytest tests/ --cov=graphJudge_Phase --cov-report=html
```

## ðŸ“ Test Output

Running the tests will generate a structured output directory:

test_results/
â””â”€â”€ run_YYYYMMDD_HHMMSS/
â”œâ”€â”€ reports/
â”‚ â”œâ”€â”€ html_report.html # HTML test report
â”‚ â”œâ”€â”€ junit_report.xml # JUnit XML report
â”‚ â””â”€â”€ test_summary.json # Test summary
â”œâ”€â”€ logs/ # Test logs
â”œâ”€â”€ coverage/ # Coverage reports
â”‚ â””â”€â”€ html/ # HTML coverage report
â””â”€â”€ artifacts/ # Test artifacts


## ðŸ§ª Test Types

### Unit Tests
- Isolated tests for each module  
- Mocked and isolated scenarios  
- Boundary and error case coverage  

### Integration Tests
- Inter-module interaction tests  
- End-to-end workflow tests  
- Data flow consistency tests  

### Compatibility Tests
- Compatibility with original `run_gj.py` output format  
- Environment variable handling compatibility  
- API behavior consistency  

### Performance Tests
- Batch processing performance  
- Memory usage stability  
- Concurrency efficiency  

## ðŸ“ Test Development Guide

### Adding New Tests

1. Choose or create the appropriate test file  
2. Use shared fixtures from `conftest.py`  
3. Follow existing naming conventions  
4. Include docstrings describing each test  
5. Cover both positive and negative cases  

### Test Naming Convention

```python
class TestModuleName:
    """Test cases for ModuleName functionality."""

    def test_function_specific_case(self):
        """Test specific behavior of function."""
        pass

    @pytest.mark.asyncio
    async def test_async_functionality(self):
        """Test async function behavior."""
        pass
```

### Mocking Guidelines

- Use `mock_async_perplexity_judge` fixture for async tests  
- Use `MockPerplexityResponse` to simulate API responses  
- Use `PerplexityTestBase` for full setup and teardown  

## ðŸ”§ Troubleshooting

### Common Issues

1. **Import errors**: Ensure you run tests from the `tests/` directory with correct environment variables.  
2. **API errors**: Tests use mock modeâ€”no real API key needed.  
3. **File permission issues**: Ensure write permissions for test directories.  
4. **Missing dependencies**: Install test requirements:  
   ```bash
   pip install pytest pytest-cov pytest-html pytest-asyncio
   ```

### Debugging Tips

- Use `-v` and `-s` flags for detailed output  
- Insert `pytest.set_trace()` to drop into a debugger  
- Check generated reports for failure details  

## âœ… Validation Checklist

Before committing, ensure:

- [ ] All tests pass  
- [ ] Coverage meets target (>90%)  
- [ ] New features have corresponding tests  
- [ ] Test documentation is up to date  
- [ ] Compatibility with original functionality verified  

## ðŸ“‹ Test Specification Comparison

### Coverage vs. original `test_run_gj.py`

| Test Category               | Original Count | Modular Count | Status      |
|-----------------------------|----------------|---------------|-------------|
| Core judgment functionality| 15             | 18            | âœ… Extended |
| Explainable judgment        | 12             | 15            | âœ… Extended |
| Input validation            | 8              | 12            | âœ… Extended |
| File handling               | 6              | 10            | âœ… Extended |
| Error handling              | 5              | 8             | âœ… Extended |
| Integration tests           | 4              | 6             | âœ… Extended |
| Gold label bootstrapping    | 8              | 12            | âœ… Extended |
| **Total**                   | **58**         | **81**        | âœ… Full coverage & extension |

The modular test suite not only covers all original tests but also adds extra cases to ensure the correctness and stability of the modular architecture.